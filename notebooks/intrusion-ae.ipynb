{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCjmVnKRWe3c",
    "outputId": "d259c5af-71d6-4442-ec8f-02028ec8482d"
   },
   "outputs": [],
   "source": [
    "# Download the IDS 2017 dataset\n",
    "!wget https://iscxdownloads.cs.unb.ca/iscxdownloads/CIC-IDS-2017/MachineLearningCSV.zip\n",
    "# Unzip the dataset\n",
    "!unzip MachineLearningCSV.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "i4geO0-MWq7m",
    "outputId": "2b7a69f6-640c-4291-f6ee-f9f9feba5d36"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filenames = ['MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', 'MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv', 'MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv', 'MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv','MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv', 'MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', 'MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv', 'MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv']\n",
    "df_aug = pd.read_csv(filenames[0])\n",
    "for name in filenames[1:]:\n",
    "  df = pd.read_csv(name)\n",
    "  df_aug = pd.concat([df_aug, df], axis=0)\n",
    "  \n",
    "print(df_aug.shape)\n",
    "df_aug.to_csv('IDS-2017-full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy4GnoTCWvcY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Read data\n",
    "\n",
    "print('Reading data ...')\n",
    "df = pd.read_csv('IDS-2017-full.csv',)\n",
    "print(df.columns)\n",
    "print('Reading done')\n",
    "print(df.shape)\n",
    "df=df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)\n",
    "cols = df.columns[:-1]\n",
    "RANDOM_SEED = 41\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[' Label'] = le.fit_transform(df[' Label'])\n",
    "Y = df[' Label']\n",
    "X = df.drop([' Label'], axis=1)\n",
    "\n",
    "\n",
    "X=X.astype('float64')\n",
    "\n",
    "X.fillna(0,inplace=True)\n",
    "\n",
    "#Replace inf values (with NaN ?)\n",
    "X=X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#Fill NaN\n",
    "X.fillna(0.0, inplace=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpTeZDI51q9M"
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "appended = np.append(X, Y[:, newaxis], axis=1)\n",
    "appended_train = np.append(X_train, Y_train[:, newaxis],  axis=1)\n",
    "print(appended.shape)\n",
    "print(appended_train.shape)\n",
    "\n",
    "appended_rows = appended.view([('', appended.dtype)] * appended.shape[1])\n",
    "appended_train_rows = appended_train.view([('', appended_train.dtype)] * appended_train.shape[1])\n",
    "appended_test = np.setdiff1d(appended_rows, appended_train_rows).view(appended.dtype).reshape(-1, appended.shape[1])\n",
    "X_test = appended_test[:,:-1]\n",
    "Y_test = appended_test[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "6rmHEuivO9Wl",
    "outputId": "d99f4142-2f29-4b92-9cba-155e6d0f09a1"
   },
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "X_train=pd.DataFrame(scaler.fit_transform(X_train),columns=cols)\n",
    "X_test=pd.DataFrame(scaler.transform(X_test),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_T4rSFRXkDA"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Y_train_generic = np.where(Y_train > 0, 1, 0)\n",
    "Y_test_generic = np.where(Y_test > 0, 1, 0)\n",
    "X_temp = X_train[Y_train_generic==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgI75KuVPYNp"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "\n",
    "generic_in = Input(shape=(X_train.shape[1],))\n",
    "e1 = Dense(52, activation='sigmoid')(generic_in)\n",
    "h = Dense(26, activation='relu')(e1)\n",
    "d1 = Dense(52, activation='relu')(h)\n",
    "generic_out = Dense(X_train.shape[1], activation='sigmoid')(d1)\n",
    "\n",
    "generic_model = Model(inputs=generic_in, outputs=generic_out)\n",
    "generic_model.compile(optimizer='adam', loss='mse', metrics=['mse']) \n",
    "generic_model.summary()\n",
    "history = generic_model.fit(X_temp, X_temp, batch_size=64, epochs=30, verbose=1)\n",
    "generic_model.save('generic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ov-B_K_QPgCR"
   },
   "outputs": [],
   "source": [
    "dos_map = {0: 0, 1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 0, 8: 6, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}\n",
    "brute_map = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 2, 12: 0, 13: 0, 14: 0}\n",
    "web_map = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 2, 14: 3}\n",
    "\n",
    "Y_train_dos = np.array(list(map(lambda d: dos_map[d], Y_train)))\n",
    "Y_test_dos = np.array(list(map(lambda d: dos_map[d], Y_test)))\n",
    "Y_train_brute = np.array(list(map(lambda d: brute_map[d], Y_train)))\n",
    "Y_test_brute = np.array(list(map(lambda d: brute_map[d], Y_test)))\n",
    "Y_train_web = np.array(list(map(lambda d: web_map[d], Y_train)))\n",
    "Y_test_web = np.array(list(map(lambda d: web_map[d], Y_test)))\n",
    "Y_train_port = np.array(list(map(lambda d: 1 if d==10 else 0, Y_train)))\n",
    "Y_test_port = np.array(list(map(lambda d: 1 if d==10 else 0, Y_test)))\n",
    "Y_train_bot = np.array(list(map(lambda d: 1 if d==1 else 0, Y_train)))\n",
    "Y_test_bot = np.array(list(map(lambda d: 1 if d==1 else 0, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GKLoT7AePplD",
    "outputId": "1aa8ef36-8202-4a68-a7e3-4bb010b7c1a8"
   },
   "outputs": [],
   "source": [
    "X_temp = X_train[Y_train_dos>0]\n",
    "dos_in = Input(shape=(X_train.shape[1],))\n",
    "e_dos = Dense(52, activation='sigmoid')(dos_in)\n",
    "h_dos = Dense(26, activation='relu')(e_dos)\n",
    "d_dos = Dense(52, activation='relu')(h_dos)\n",
    "dos_out = Dense(X_train.shape[1], activation='sigmoid')(d_dos)\n",
    "\n",
    "dos_model = Model(inputs=dos_in, outputs=dos_out)\n",
    "dos_model.compile(optimizer='adam', loss='mse', metrics=['mse']) \n",
    "dos_model.summary()\n",
    "history_dos = dos_model.fit(X_temp, X_temp, batch_size=64, epochs=30, verbose=1)\n",
    "dos_model.save('dos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zwlIOjR4PqIh",
    "outputId": "d4b622a6-cbc8-49eb-beee-32b08fabf971"
   },
   "outputs": [],
   "source": [
    "X_temp = X_train[Y_train_brute>0]\n",
    "brute_in = Input(shape=(X_train.shape[1],))\n",
    "e_brute = Dense(52, activation='sigmoid')(brute_in)\n",
    "h_brute = Dense(26, activation='relu')(e_brute)\n",
    "d_brute = Dense(52, activation='relu')(h_brute)\n",
    "brute_out = Dense(X_train.shape[1], activation='sigmoid')(d_brute)\n",
    "\n",
    "brute_model = Model(inputs=brute_in, outputs=brute_out)\n",
    "brute_model.compile(optimizer='adam', loss='mse', metrics=['mse']) \n",
    "brute_model.summary()\n",
    "history_brute = brute_model.fit(X_temp, X_temp, batch_size=64, epochs=30, verbose=1)\n",
    "brute_model.save('brute.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iLtJ-W8hPuBd",
    "outputId": "c1c58829-8929-409c-fd94-b991d873b060"
   },
   "outputs": [],
   "source": [
    "X_temp = X_train[Y_train_web>0]\n",
    "web_in = Input(shape=(X_train.shape[1],))\n",
    "e_web = Dense(52, activation='sigmoid')(web_in)\n",
    "h_web = Dense(26, activation='relu')(e_web)\n",
    "d_web = Dense(52, activation='relu')(h_web)\n",
    "web_out = Dense(X_train.shape[1], activation='sigmoid')(d_web)\n",
    "\n",
    "web_model = Model(inputs=web_in, outputs=web_out)\n",
    "web_model.compile(optimizer='adam', loss='mse', metrics=['mse']) \n",
    "web_model.summary()\n",
    "history_web = web_model.fit(X_temp, X_temp, batch_size=64, epochs=60, verbose=1)\n",
    "web_model.save('web.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ewCFZ4gKPxPW",
    "outputId": "5aef8f22-845f-4d4f-9961-639ed5f54ed4"
   },
   "outputs": [],
   "source": [
    "X_temp = X_train[Y_train_port>0]\n",
    "port_in = Input(shape=(X_train.shape[1],))\n",
    "e_port = Dense(52, activation='sigmoid')(port_in)\n",
    "h_port = Dense(26, activation='relu')(e_port)\n",
    "d_port = Dense(52, activation='relu')(h_port)\n",
    "port_out = Dense(X_train.shape[1], activation='sigmoid')(d_port)\n",
    "\n",
    "port_model = Model(inputs=port_in, outputs=port_out)\n",
    "port_model.compile(optimizer='adam', loss='mse', metrics=['mse']) \n",
    "port_model.summary()\n",
    "history_port = port_model.fit(X_temp, X_temp, batch_size=64, epochs=30, verbose=1)\n",
    "port_model.save('port.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vrHyMmzpP0bv",
    "outputId": "ed4e607a-a50f-4ca7-9a79-0e2a758243bb"
   },
   "outputs": [],
   "source": [
    "X_temp = X_train[Y_train_bot>0]\n",
    "bot_in = Input(shape=(X_train.shape[1],))\n",
    "e_bot = Dense(52, activation='sigmoid')(bot_in)\n",
    "h_bot = Dense(26, activation='relu')(e_bot)\n",
    "d_bot = Dense(52, activation='relu')(h_bot)\n",
    "bot_out = Dense(X_train.shape[1], activation='sigmoid')(d_bot)\n",
    "\n",
    "bot_model = Model(inputs=bot_in, outputs=bot_out)\n",
    "bot_model.compile(optimizer='adam', loss='mse', metrics=['mse']) \n",
    "bot_model.summary()\n",
    "history_bot = bot_model.fit(X_temp, X_temp, batch_size=64, epochs=60, verbose=1)\n",
    "bot_model.save('bot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "OQWtIaI5P4Wf",
    "outputId": "50f4af9e-5fae-4306-a6fe-eb1f7c918213"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "generic_model_hidden = Model(inputs=generic_model.input, outputs=generic_model.layers[-3].output)\n",
    "H_train = generic_model_hidden.predict(X_train)\n",
    "H_test = generic_model_hidden.predict(X_test)\n",
    "\n",
    "print(H_train.shape)\n",
    "print(H_test.shape)\n",
    "\n",
    "dos_model_hidden = Model(inputs=dos_model.input, outputs=dos_model.layers[-3].output)\n",
    "brute_model_hidden = Model(inputs=brute_model.input, outputs=brute_model.layers[-3].output)\n",
    "web_model_hidden = Model(inputs=web_model.input, outputs=web_model.layers[-3].output)\n",
    "port_model_hidden = Model(inputs=port_model.input, outputs=port_model.layers[-3].output)\n",
    "bot_model_hidden = Model(inputs=bot_model.input, outputs=bot_model.layers[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "r_Ia_CMQQJoK",
    "outputId": "44ea2b25-74a9-426b-f14f-693c1273f0d8"
   },
   "outputs": [],
   "source": [
    "H_train_temp = dos_model_hidden.predict(X_train)\n",
    "H_test_temp = dos_model_hidden.predict(X_test)\n",
    "\n",
    "H_train_concat = np.append(H_train, H_train_temp, axis=1)\n",
    "H_test_concat = np.append(H_test, H_test_temp, axis=1)\n",
    "print(H_train_concat.shape)\n",
    "print(H_test_concat.shape)\n",
    "\n",
    "H_train_temp = brute_model_hidden.predict(X_train)\n",
    "H_test_temp = brute_model_hidden.predict(X_test)\n",
    "\n",
    "H_train_concat = np.append(H_train_concat, H_train_temp, axis=1)\n",
    "H_test_concat = np.append(H_test_concat, H_test_temp, axis=1)\n",
    "print(H_train_concat.shape)\n",
    "print(H_test_concat.shape)\n",
    "\n",
    "H_train_temp = web_model_hidden.predict(X_train)\n",
    "H_test_temp = web_model_hidden.predict(X_test)\n",
    "\n",
    "H_train_concat = np.append(H_train_concat, H_train_temp, axis=1)\n",
    "H_test_concat = np.append(H_test_concat, H_test_temp, axis=1)\n",
    "print(H_train_concat.shape)\n",
    "print(H_test_concat.shape)\n",
    "\n",
    "H_train_temp = port_model_hidden.predict(X_train)\n",
    "H_test_temp = port_model_hidden.predict(X_test)\n",
    "\n",
    "H_train_concat = np.append(H_train_concat, H_train_temp, axis=1)\n",
    "H_test_concat = np.append(H_test_concat, H_test_temp, axis=1)\n",
    "print(H_train_concat.shape)\n",
    "print(H_test_concat.shape)\n",
    "\n",
    "H_train_temp = bot_model_hidden.predict(X_train)\n",
    "H_test_temp = bot_model_hidden.predict(X_test)\n",
    "H_train_concat = np.append(H_train_concat, H_train_temp, axis=1)\n",
    "H_test_concat = np.append(H_test_concat, H_test_temp, axis=1)\n",
    "print(H_train_concat.shape)\n",
    "print(H_test_concat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "id": "XoQLuwiRQLO8",
    "outputId": "c5871922-1d59-41e8-e7b4-2f916b068554"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 5, verbose=2, oob_score=True, n_jobs=-1)\n",
    "clf.fit(H_train_concat, Y_train)\n",
    "Y_pred_concat = clf.predict(H_test_concat)\n",
    "print(classification_report(Y_test, Y_pred_concat))\n",
    "print(accuracy_score(Y_test, Y_pred_concat))\n",
    "print(confusion_matrix(Y_test, Y_pred_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-GVLXtHQn_I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "intrusion-ae-sampled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
